# BATUHAN CAKIR 090190164
import numpy as np
import glob
from PIL import Image
import matplotlib.pyplot as plt

# data road join for import array
agac_yolu = glob.glob('C:/Users/BATUHAN/Desktop/gri_kaynak/dataset/agac/*')
top_yolu  = glob.glob('C:/Users/BATUHAN/Desktop/gri_kaynak/dataset/top/*')

# data join to matrix and flatting
def gorseli_matrixe_atma(path):
    column_no = 0
    sifirlar = np.zeros((10000,500))
    while True:
        if column_no ==len(path):
            break
        image = Image.open(path[column_no]).convert('L')
        img_transpose = np.ravel(image).T
        sifirlar[:,column_no] = img_transpose
        column_no +=1
    return sifirlar

# x and y class
agac_veri = gorseli_matrixe_atma(agac_yolu)   # (10000,450)
top_veri = gorseli_matrixe_atma(top_yolu),    # (10000,450)

# seperating image data train and test
agac_train = agac_veri[:,0:450].T/255.0
agac_test  = agac_veri[:,450:].T/255.0
top_train  = top_veri[:,0:450].T/255.0
top_test   = top_veri[:,450:].T/255.0

# sigmoid function
def sigmoid(z):
    s = 1.0/(1.0 + np.exp(-z))
    return s

# initialize weight and bias values with funtion
def initialize_with_zeros(dim):
    w = np.zeros((dim, 1)) 
    b = 0
    return w, b

# calculating cost and weight, bias gradients
def propagate(w, b, X, Y):
    m = X.shape[1]  
    
    A = sigmoid(np.dot(w.T, X) + b) # predicted output      # (1,450)x(450,10000)=(1,10000)
    
    cost = -1/m * np.sum(Y*np.log(A) + (1-Y) * np.log(1-A)) # Cross-entropy loss  
    
    # gradients
    dw = (np.dot(X,((A-Y).T))) / m 
    db = np.sum((A-Y)) / m          
    return dw , db , cost

# optimization part
def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):
    costs = []
    for i in range(num_iterations):
        dw, db, cost = propagate(w, b, X, Y)    
        #Updating w and b by deducting the dw #and db times learning rate from the previous #w and b
        w = w - learning_rate * dw
        b = b - learning_rate * db
        
        #Print the cost function value for each 100 iterations        
        if print_cost and i % 100 == 0:
            print("Cost after iteration %i--> %f" %(i, cost))          #cost (1,1)
            costs.append(cost)
    return w, b, costs

# prediction part
def predict(w, b, X):
    m = X.shape[1]  #10000 
    
    #replaced by the predicted output 
    Y_prediction = np.zeros((1,m))  #(1,10000)
    
    #Calculating the predicted output using the Formula 1  #This will return the values from 0 to 1
    A = sigmoid(np.dot(w.T, X) + b)       #(1,450)x(450,10000)=(1,10000)
    
    #Iterating through A and predict an 1 if the value of A is greater than 0.5 and zero 
    for i in range(A.shape[1]):  #10000
        Y_prediction[:, i] = (A[:, i] > 0.5) * 1             #(1,10000) = (1,10000)
    return Y_prediction

def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.005, print_cost = False):
    
    #Initializing the w and b as zeros
    w, b = initialize_with_zeros(X_train.shape[0])                                                 
    
    w, b, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)

    # Predicting the output for both test and training set 
    Y_prediction_train = predict(w, b, X_train)
    Y_prediction_test = predict(w, b, X_test)
    
    #Calculating the training and test set accuracy by comparing the predicted output and the original output
    print("train accuracy: % {} ".format(100 - np.mean(np.absolute(Y_prediction_train - Y_train)) * 100))
    print("test  accuracy: % {} ".format(100 - np.mean(np.absolute(Y_prediction_test - Y_test))   * 100))
    
    return Y_prediction_test, costs

Y_prediction_test, costs = model(agac_train, top_train, agac_test, top_test, num_iterations = 1000, learning_rate = 0.005, print_cost =True)

"""
iterations = range(0,1000,100)
plt.figure(figsize=(7,5)),
plt.scatter(x = iterations , y = costs , color='red')
plt.title('Scatter Plot of Cost Functions', fontsize=22)
plt.ylabel('Costs', fontsize=18)
plt.xlabel("Number of iterations", fontsize=18)
plt.show()
"""











